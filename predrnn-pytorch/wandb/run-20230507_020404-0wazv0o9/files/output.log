/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1979_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1980_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1981_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1982_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1983_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1984_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1985_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1986_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1987_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1988_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1989_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1990_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1991_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1992_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1993_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1994_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1995_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1996_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1997_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1998_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_1999_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2006_3_24hr.npz
train_data_files nums: 28
mnist test iterator, Loading data from /scratch/09012/haoli1/ERA5/val_dataset/era5_train_09012020_3_24hr.npz
NaN value num: 0
mnist train iterator, Loading data from /scratch/09012/haoli1/ERA5/dataset_6hrs/era5_train_2000_3_24hr.npz
NaN value num: 0
Iteration: 1, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: 3.67156280844938e-05, gen p mean: 0.0, mean p set: 0.4498332440853119
loss_pred:0.22444665431976318, decouple_loss:0.05404428392648697
The modified gen p mean: -0.00016950396820902824, gen p mean: 0.0, mean p set: 0.4485096037387848
loss_pred:0.22599242627620697, decouple_loss:0.054296307265758514
The modified gen p mean: -0.0003242894890718162, gen p mean: 0.0, mean p set: 0.44820359349250793
loss_pred:0.22028110921382904, decouple_loss:0.05383550375699997
/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Iteration: 2, ims.shape: (3, 56, 3, 720, 1440)
The modified gen p mean: -0.0005403285613283515, gen p mean: 0.0, mean p set: 0.4514331519603729
loss_pred:0.2301522195339203, decouple_loss:0.13558867573738098
The modified gen p mean: -0.0004079537757206708, gen p mean: 0.0, mean p set: 0.4532293379306793
loss_pred:0.21837365627288818, decouple_loss:0.1357327550649643
The modified gen p mean: -0.00045167646021582186, gen p mean: 0.0, mean p set: 0.4496879279613495
loss_pred:0.22791555523872375, decouple_loss:0.1378171443939209
Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 355, in <module>
    train_wrapper(model)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 280, in train_wrapper
    trainer.train(model, ims, real_input_flag, args, itr)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/trainer.py", line 25, in train
    cost = model.train(ims, real_input_flag)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/model_factory_multiGPU.py", line 68, in train
    loss.mean().backward()
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 39.42 GiB total capacity; 35.39 GiB already allocated; 1.43 GiB free; 36.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF