After initialize model, args.img_channel:30
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012019_3_24hr.npz
train_data_files nums: 40
mnist test iterator, Loading data from /scratch/09012/haoli1/ERA5/val_dataset/era5_train_07012020_3_24hr.npz
NaN value num: 0
mnist train iterator, Loading data from /scratch/09012/haoli1/ERA5/dataset/era5_train_09012013_3_24hr.npz
NaN value num: 0
Iteration: 1, ims.shape: (3, 48, 3, 720, 1440)
The modified gen p mean: 0.4487960636615753, gen p mean: -0.0006871205987408757, mean p set: 0.44937291741371155
loss_pred:0.16402047872543335, decouple_loss:0.08388452231884003
The modified gen p mean: 0.4483862817287445, gen p mean: -0.0005928967730142176, mean p set: 0.4489628076553345
loss_pred:0.16933511197566986, decouple_loss:0.08377227932214737
The modified gen p mean: 0.44789621233940125, gen p mean: -0.0009437067783437669, mean p set: 0.44847285747528076
loss_pred:0.16385488212108612, decouple_loss:0.08295463025569916
/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Iteration: 2, ims.shape: (3, 48, 3, 720, 1440)
The modified gen p mean: 0.44767263531684875, gen p mean: -0.0016154485056176782, mean p set: 0.44824886322021484
The modified gen p mean: 0.44674572348594666, gen p mean: -0.0015367104206234217, mean p set: 0.4473215639591217
loss_pred:0.17258970439434052, decouple_loss:0.26839444041252136
loss_pred:0.16924530267715454, decouple_loss:0.26449915766716003
Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 338, in <module>
    train_wrapper(model)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 277, in train_wrapper
    trainer.train(model, ims, real_input_flag, args, itr)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/trainer.py", line 25, in train
    cost = model.train(ims, real_input_flag)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/model_factory_multiGPU.py", line 59, in train
    loss, loss_pred, decouple_loss = self.network(frames_tensor, mask_tensor, istrain=True)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/_utils.py", line 461, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/predrnn_mgpu.py", line 158, in forward
    h_t[i], c_t[i], memory, delta_c, delta_m = self.cell_list[i](h_t[i - 1], h_t[i], c_t[i], memory)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/layers/SpatioTemporalLSTMCell_v2.py", line 48, in forward
    h_concat = self.conv_h(h_t)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 189, in forward
    return F.layer_norm(
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/functional.py", line 2503, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 39.42 GiB total capacity; 37.59 GiB already allocated; 15.00 MiB free; 37.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF