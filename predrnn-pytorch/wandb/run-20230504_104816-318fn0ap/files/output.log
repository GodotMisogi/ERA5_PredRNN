/scratch/09012/haoli1/ERA5/dataset/era5_train_01012001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_01012020_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_03012020_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_05012020_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_07012020_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_09012019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012000_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012001_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012002_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012003_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012004_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012005_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012006_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012007_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012008_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012009_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012010_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012011_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012012_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012013_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012014_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012015_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012016_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012017_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012018_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012019_3_24hr.npz
/scratch/09012/haoli1/ERA5/dataset/era5_train_11012020_3_24hr.npz
train_data_files nums: 124
mnist test iterator, Loading data from /scratch/09012/haoli1/ERA5/val_dataset/era5_train_09012020_3_24hr.npz
NaN value num: 0
mnist train iterator, Loading data from /scratch/09012/haoli1/ERA5/dataset/era5_train_09012015_3_24hr.npz
NaN value num: 0
Iteration: 1, ims.shape: (3, 48, 3, 720, 1440)
The modified gen p mean: 0.4483431875705719, gen p mean: 0.0005804072134196758, mean p set: 0.448919415473938
loss_pred:0.16268029808998108, decouple_loss:0.0692039206624031
The modified gen p mean: 0.44746705889701843, gen p mean: 0.0005297079915180802, mean p set: 0.4480428397655487
loss_pred:0.16855792701244354, decouple_loss:0.06895661354064941
The modified gen p mean: 0.44708922505378723, gen p mean: 0.00036580252344720066, mean p set: 0.4476655125617981
loss_pred:0.16109229624271393, decouple_loss:0.06857459247112274
/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Iteration: 2, ims.shape: (3, 48, 3, 720, 1440)
The modified gen p mean: 0.4471031427383423, gen p mean: 5.1723469368880615e-05, mean p set: 0.44767823815345764
loss_pred:0.16581475734710693, decouple_loss:0.21814559400081635
The modified gen p mean: 0.4462103545665741, gen p mean: 0.00014594978711102158, mean p set: 0.4467865526676178
loss_pred:0.1788129061460495, decouple_loss:0.21543078124523163
The modified gen p mean: 0.4483198821544647, gen p mean: -5.417287866293918e-06, mean p set: 0.44889581203460693
loss_pred:0.17862358689308167, decouple_loss:0.2185416966676712
Iteration: 3, ims.shape: (3, 48, 3, 720, 1440)
The modified gen p mean: 0.44737207889556885, gen p mean: -0.0038167533930391073, mean p set: 0.4479483664035797
loss_pred:0.15415547788143158, decouple_loss:0.31280532479286194
The modified gen p mean: 0.4481232166290283, gen p mean: -0.0038285041227936745, mean p set: 0.44869908690452576
loss_pred:0.16857066750526428, decouple_loss:0.3136458396911621
The modified gen p mean: 0.44705653190612793, gen p mean: -0.0037271420005708933, mean p set: 0.4476326107978821
loss_pred:0.15573513507843018, decouple_loss:0.31209734082221985
Iteration: 4, ims.shape: (3, 48, 3, 720, 1440)
The modified gen p mean: 0.44851118326187134, gen p mean: -0.001325050019659102, mean p set: 0.44908660650253296
loss_pred:0.16538801789283752, decouple_loss:0.3277876079082489
The modified gen p mean: 0.44742560386657715, gen p mean: -0.0012371945194900036, mean p set: 0.4480014741420746
loss_pred:0.1498757004737854, decouple_loss:0.3292699456214905
The modified gen p mean: 0.44786784052848816, gen p mean: -0.0012448285706341267, mean p set: 0.44844329357147217
loss_pred:0.1583443284034729, decouple_loss:0.32903149724006653
Traceback (most recent call last):
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 350, in <module>
    train_wrapper(model)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/run1.py", line 278, in train_wrapper
    trainer.train(model, ims, real_input_flag, args, itr)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/trainer.py", line 25, in train
    cost = model.train(ims, real_input_flag)
  File "/work/09012/haoli1/ls6/ERA5_PredRNN/predrnn-pytorch/core/models/model_factory_multiGPU.py", line 68, in train
    loss.mean().backward()
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/work/09012/haoli1/ls6/Pyt/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 39.42 GiB total capacity; 34.58 GiB already allocated; 1.48 GiB free; 36.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF